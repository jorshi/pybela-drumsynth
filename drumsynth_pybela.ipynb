{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyBela Drum Synth\n",
    "\n",
    "In this notebook we'll look at using pyBela to capture onset features from the drumsynth project. This includes a Bela project that has been updated to log onset energy and spectral centroid audio features computed at detected onsets using `Watcher`. We'll look at training a small MLP to regress synthesis parameters based on those features.\n",
    "\n",
    "First, establish a connection with Bela and copy the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ssh-keyscan bela.local >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rsync -rvL --exclude 'main.cpp' --exclude 'DrumControllerInference.cpp' src/ root@bela.local:Bela/projects/pybela-drumsynth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Collect dataset\n",
    "To collect data run the `pybela-drumsynth` project on Bela (you can do so from web-based IDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybela import Logger\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "logger=Logger()\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"onsetEnergy\", \"spectralCentroid\"]\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record data for three different classes -- run this cell three times and update the classes [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 2\n",
    "read_time = 10\n",
    "\n",
    "file_paths = logger.start_logging(variables=variables)\n",
    "await asyncio.sleep(read_time)\n",
    "logger.stop_logging()\n",
    "\n",
    "# Extract the data from the binary\n",
    "raw_sc = logger.read_binary_file(file_path=file_paths[\"local_paths\"][\"spectralCentroid\"], timestamp_mode=\"sparse\")\n",
    "raw_oe = logger.read_binary_file(file_path=file_paths[\"local_paths\"][\"onsetEnergy\"], timestamp_mode=\"sparse\")\n",
    "\n",
    "spectral_centroid = []\n",
    "onset_energy = []\n",
    "\n",
    "# Loop through all the buffers and each data point in each buffer.\n",
    "# PyBela appends zeros to the end of buffers so disregard those if values\n",
    "# in each variable are both zeros.\n",
    "for sc_buffer, oe_buffer in zip(raw_sc['buffers'], raw_oe['buffers']):\n",
    "    for x, y in zip(sc_buffer['data'], oe_buffer['data']):\n",
    "        if x == 0 and y == 0:\n",
    "            continue\n",
    "        spectral_centroid.append(x)\n",
    "        onset_energy.append(y)\n",
    "\n",
    "assert len(spectral_centroid) == len(onset_energy)\n",
    "print(f\"Found {len(spectral_centroid)} points\")\n",
    "\n",
    "data[class_num] = {\n",
    "    \"sc\": spectral_centroid,\n",
    "    \"oe\": onset_energy,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Visualize Data\n",
    "\n",
    "Let's look at the data we collected from audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data.items():\n",
    "    plt.scatter(v[\"sc\"], v[\"oe\"], label=f\"Class {k}\")\n",
    "    \n",
    "plt.xlabel(\"Spectral Centroid (Bin Number)\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.title(\"Scatter Plot of Extracted Onset Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Train model\n",
    "\n",
    "Now let's train a model to map from these values to different synth presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import pprint as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_1 = [0.30, 0.60, 0.30, 0.92, 0.75, 0.50, 0.50]\n",
    "preset_2 = [0.77, 0.35, 0.12, 0.37, 0.24, 0.76, 0.64]\n",
    "preset_3 = [0.16, 0.50, 0.53, 0.77, 0.20, 0.30, 0.50]\n",
    "presets = [preset_1, preset_2, preset_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthOnsetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset that returns input features and groud truth synth parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, presets, device):\n",
    "        super().__init__()\n",
    "        assert len(data) == len(presets), \"Must have same number of classes as synth presets\"\n",
    "\n",
    "        self.device = device\n",
    "        self.presets = torch.tensor(presets, device=self.device).float()\n",
    "        self.features = []\n",
    "        self.classes = []\n",
    "    \n",
    "        for k, v in data.items():\n",
    "            for features in zip(v[\"sc\"], v[\"oe\"]):\n",
    "                self.classes.append(k)\n",
    "                self.features.append(features)\n",
    "        self.features = torch.tensor(self.features, device=self.device).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.presets[self.classes[idx]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "dataset = SynthOnsetDataset(data, presets, device)\n",
    "\n",
    "# Split dataset\n",
    "train_count = int(0.9 * dataset.__len__())\n",
    "test_count = dataset.__len__() - train_count\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, (train_count, test_count)\n",
    ")\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A Multilayer Perceptron for Parameter Estimation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size: int,  # Input parameter size\n",
    "        hidden_size: int,  # Hidden layer size\n",
    "        out_size: int,  # Output parameter size\n",
    "        num_layers: int,  # Number of hidden layers\n",
    "        activation: torch.nn.Module = torch.nn.LeakyReLU(),  # Activation function\n",
    "    ):\n",
    "        super().__init__()\n",
    "        channels = [in_size] + (num_layers) * [hidden_size]\n",
    "        net = []\n",
    "        for i in range(num_layers):\n",
    "            net.append(torch.nn.Linear(channels[i], channels[i + 1]))\n",
    "            net.append(torch.nn.LayerNorm(channels[i + 1], elementwise_affine=False))\n",
    "            net.append(activation)\n",
    "\n",
    "        net.append(torch.nn.Linear(channels[-1], out_size))\n",
    "        self.in_size = in_size\n",
    "        self.net = torch.nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        y = self.net(x)\n",
    "        y = (torch.tanh(y) + 1.0) * 0.5 # Apply tanh to constrain range and scale to [0,1]\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[0]\n",
    "model = MLP(x.shape[0], 32, y.shape[0], 2).to(device)\n",
    "\n",
    "y_hat = model(x)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "\n",
    "pbar = tqdm(range(epochs))\n",
    "for i in pbar:\n",
    "\n",
    "    # Training step\n",
    "    error_log = []\n",
    "    for x, y in train_loader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = model(x)\n",
    "\n",
    "        # Compute error and gradients\n",
    "        error = loss_fn(y_hat, y)\n",
    "        error.backward()\n",
    "\n",
    "        # Do optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        error_log.append(error.detach().cpu().item())\n",
    "\n",
    "    epoch_loss = np.mean(error_log)\n",
    "    pbar.set_description(f\"Epoch {i} | Train Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "error_log = []\n",
    "for x, y, in test_loader:\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(x)\n",
    "\n",
    "    error = loss_fn(y_hat, y)\n",
    "    error_log.append(error.detach().cpu().item())\n",
    "\n",
    "print(f\"Model error: {np.mean(error_log):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device='cpu')\n",
    "model.eval()\n",
    "script = torch.jit.script(model)\n",
    "path = \"drum_model.jit\"\n",
    "script.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.load(path) # check model is properly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rsync -av ./drum_model.jit root@bela.local:Bela/projects/pybela-drumsynth-inference/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
